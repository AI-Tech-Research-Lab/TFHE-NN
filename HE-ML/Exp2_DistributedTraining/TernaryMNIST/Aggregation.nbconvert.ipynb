{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-25T09:35:16.175532Z",
     "iopub.status.busy": "2023-01-25T09:35:16.174019Z",
     "iopub.status.idle": "2023-01-25T09:35:19.249657Z",
     "shell.execute_reply": "2023-01-25T09:35:19.248993Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-25 09:35:16.705523: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-25 09:35:16.877005: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-01-25 09:35:17.767330: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-25 09:35:17.771919: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-25 09:35:17.771932: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os, sys\n",
    "module_path = os.path.abspath(os.path.join('../../..'))\n",
    "sys.path.append(module_path)\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import copy\n",
    "import pandas as pd\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from pycrcnn.he.he import TFHEnuFHE\n",
    "from pycrcnn.he.tfhe_value import TFHEValue\n",
    "from pycrcnn.he.alu import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HE Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-25T09:35:19.254733Z",
     "iopub.status.busy": "2023-01-25T09:35:19.254096Z",
     "iopub.status.idle": "2023-01-25T09:35:19.724028Z",
     "shell.execute_reply": "2023-01-25T09:35:19.722311Z"
    },
    "executionInfo": {
     "elapsed": 3124,
     "status": "ok",
     "timestamp": 1651862255412,
     "user": {
      "displayName": "Luca Colombo",
      "userId": "05787806710317186015"
     },
     "user_tz": -120
    },
    "id": "gJbSks0DFdDs"
   },
   "outputs": [],
   "source": [
    "HE_client = TFHEnuFHE(22)\n",
    "\n",
    "with open(\"res/keys/secret_key\", \"rb\") as f:\n",
    "    HE_client.secret_key = HE_client.ctx.load_secret_key(f)\n",
    "    \n",
    "with open(\"res/keys/cloud_key\", \"rb\") as f:\n",
    "    HE_client.cloud_key = HE_client.ctx.load_cloud_key(f)\n",
    "\n",
    "cloud_key = HE_client.cloud_key\n",
    "HE_client.generate_vm(cloud_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-25T09:35:19.728772Z",
     "iopub.status.busy": "2023-01-25T09:35:19.728166Z",
     "iopub.status.idle": "2023-01-25T09:35:53.976001Z",
     "shell.execute_reply": "2023-01-25T09:35:53.968649Z"
    },
    "executionInfo": {
     "elapsed": 28535,
     "status": "ok",
     "timestamp": 1651862283941,
     "user": {
      "displayName": "Luca Colombo",
      "userId": "05787806710317186015"
     },
     "user_tz": -120
    },
    "id": "tsfVVfwUFeyB"
   },
   "outputs": [],
   "source": [
    "num1 = HE_client.encrypt(1)\n",
    "num2 = HE_client.encode(6)\n",
    "sum = num1+num2\n",
    "mul = num1*num2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EncNet Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-25T09:35:53.982539Z",
     "iopub.status.busy": "2023-01-25T09:35:53.982288Z",
     "iopub.status.idle": "2023-01-25T09:35:54.014955Z",
     "shell.execute_reply": "2023-01-25T09:35:54.012615Z"
    }
   },
   "outputs": [],
   "source": [
    "SHRT_MAX = 32767\n",
    "SHRT_MIN = (-SHRT_MAX - 1 )\n",
    "\n",
    "# Int square root\n",
    "def isqrt(n):\n",
    "    x = n\n",
    "    y = (x + 1) // 2\n",
    "    while y < x:\n",
    "        x = y\n",
    "        y = (x + n // x) // 2\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-25T09:35:54.022330Z",
     "iopub.status.busy": "2023-01-25T09:35:54.021809Z",
     "iopub.status.idle": "2023-01-25T09:35:54.075875Z",
     "shell.execute_reply": "2023-01-25T09:35:54.073248Z"
    }
   },
   "outputs": [],
   "source": [
    "# Encrypted PLA tanh Activation function\n",
    "def encrypted_tanh(act_in, in_dim, out_dim):\n",
    "    y_max, y_min = HE_client.encode(128), HE_client.encode(-127)\n",
    "    intervals = HE_client.encode_matrix([128, 75, 32, -31, -74, -127])\n",
    "    slopes_inv = HE_client.encode_matrix([128, 8, 2, 1, 2, 8, 128])\n",
    "    act_out, act_grad_inv = np.full((act_in.shape[0], out_dim), y_max), np.full((act_in.shape[0], out_dim), slopes_inv[0])\n",
    "\n",
    "    for i in range(len(act_in)):\n",
    "        for j in range(len(act_in[i].squeeze())):\n",
    "            val = act_in[i].squeeze()[j] / ((1 << 8) * in_dim)\n",
    "\n",
    "            lt0 = val < intervals[0]\n",
    "            act_out[i][j] = TFHEValue(HE_client.vm.gate_mux(lt0, (val / 4).value, act_out[i][j].value), val.vm, val.n_bits)\n",
    "            act_grad_inv[i][j] = TFHEValue(HE_client.vm.gate_mux(lt0, slopes_inv[1].value, act_grad_inv[i][j].value), val.vm, val.n_bits)\n",
    "\n",
    "            lt1 = val < intervals[1]\n",
    "            act_out[i][j] = TFHEValue(HE_client.vm.gate_mux(lt1, val.value, act_out[i][j].value), val.vm, val.n_bits)\n",
    "            act_grad_inv[i][j] = TFHEValue(HE_client.vm.gate_mux(lt1, slopes_inv[2].value, act_grad_inv[i][j].value), val.vm, val.n_bits)\n",
    "\n",
    "            lt2 = val < intervals[2]\n",
    "            act_out[i][j] = TFHEValue(HE_client.vm.gate_mux(lt2, (val * 2).value, act_out[i][j].value), val.vm, val.n_bits)\n",
    "            act_grad_inv[i][j] = TFHEValue(HE_client.vm.gate_mux(lt2, slopes_inv[3].value, act_grad_inv[i][j].value), val.vm, val.n_bits)\n",
    "\n",
    "            lt3 = val < intervals[3]\n",
    "            act_out[i][j] = TFHEValue(HE_client.vm.gate_mux(lt3, val.value, act_out[i][j].value), val.vm, val.n_bits)\n",
    "            act_grad_inv[i][j] = TFHEValue(HE_client.vm.gate_mux(lt3, slopes_inv[4].value, act_grad_inv[i][j].value), val.vm, val.n_bits)\n",
    "\n",
    "            lt4 = val < intervals[4]\n",
    "            act_out[i][j] = TFHEValue(HE_client.vm.gate_mux(lt4, (val / 4).value, act_out[i][j].value), val.vm, val.n_bits)\n",
    "            act_grad_inv[i][j] = TFHEValue(HE_client.vm.gate_mux(lt4, slopes_inv[5].value, act_grad_inv[i][j].value), val.vm, val.n_bits)\n",
    "\n",
    "            lt5 = val < intervals[5]\n",
    "            act_out[i][j] = TFHEValue(HE_client.vm.gate_mux(lt5, y_min.value, act_out[i][j].value), val.vm, val.n_bits)\n",
    "            act_grad_inv[i][j] = TFHEValue(HE_client.vm.gate_mux(lt5, slopes_inv[6].value, act_grad_inv[i][j].value), val.vm, val.n_bits)\n",
    "        \n",
    "    return act_out, act_grad_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-25T09:35:54.079977Z",
     "iopub.status.busy": "2023-01-25T09:35:54.078994Z",
     "iopub.status.idle": "2023-01-25T09:35:54.100001Z",
     "shell.execute_reply": "2023-01-25T09:35:54.096663Z"
    }
   },
   "outputs": [],
   "source": [
    "# Encrypted L2 Loss Function\n",
    "def encrypted_L2(y_true, net_out):\n",
    "    loss = np.full((y_true.shape[0], y_true.shape[1]), HE_client.encode(0))\n",
    "    for i in range(len(y_true)):\n",
    "        for j in range(len(y_true[i])):\n",
    "            loss[i][j] = net_out[i].squeeze()[j] - y_true[i][j]\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-25T09:35:54.105914Z",
     "iopub.status.busy": "2023-01-25T09:35:54.105432Z",
     "iopub.status.idle": "2023-01-25T09:35:54.132006Z",
     "shell.execute_reply": "2023-01-25T09:35:54.128656Z"
    }
   },
   "outputs": [],
   "source": [
    "# Encrypted MaxPool Layer\n",
    "class EncryptedMaxPoolLayer:\n",
    "    def __init__(self, kernel_size, stride=(1, 1)):\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, batch):\n",
    "        return np.array([_max(image, self.kernel_size, self.stride) for image in batch])\n",
    "\n",
    "    def backward(self, loss, lr_inv):\n",
    "        return loss\n",
    "\n",
    "def _max(image, kernel_size, stride):\n",
    "    x_s = stride[1]\n",
    "    y_s = stride[0]\n",
    "\n",
    "    x_k = kernel_size[1]\n",
    "    y_k = kernel_size[0]\n",
    "\n",
    "    # print(image)\n",
    "    x_d = len(image[0])\n",
    "    y_d = len(image)\n",
    "\n",
    "    x_o = ((x_d - x_k) // x_s) + 1\n",
    "    y_o = ((y_d - y_k) // y_s) + 1\n",
    "\n",
    "    def get_submatrix(matrix, x, y):\n",
    "        index_row = y * y_s\n",
    "        index_column = x * x_s\n",
    "        return matrix[index_row: index_row + y_k, index_column: index_column + x_k]\n",
    "\n",
    "    return [[encrypted_max(get_submatrix(image, x, y).flatten()) for x in range(0, x_o)] for y in range(0, y_o)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-25T09:35:54.135440Z",
     "iopub.status.busy": "2023-01-25T09:35:54.134946Z",
     "iopub.status.idle": "2023-01-25T09:35:54.152012Z",
     "shell.execute_reply": "2023-01-25T09:35:54.148439Z"
    }
   },
   "outputs": [],
   "source": [
    "# Encrypted Flatten Layer\n",
    "class EncryptedFlattenLayer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, flatten_in):\n",
    "        return flatten_in.reshape(flatten_in.shape[0], flatten_in.shape[1]*flatten_in.shape[2])\n",
    "\n",
    "    def backward(self, loss, lr_inv):\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-25T09:35:54.155386Z",
     "iopub.status.busy": "2023-01-25T09:35:54.154894Z",
     "iopub.status.idle": "2023-01-25T09:35:54.176012Z",
     "shell.execute_reply": "2023-01-25T09:35:54.172651Z"
    }
   },
   "outputs": [],
   "source": [
    "# Encrypted FC Layer\n",
    "class EncryptedFCLayer:\n",
    "    def __init__(self, in_dim, out_dim, last_layer = False):\n",
    "        self.in_dim, self.out_dim = in_dim, out_dim\n",
    "        self.last_layer = last_layer\n",
    "        self.weights = np.zeros((in_dim, out_dim)).astype(int)\n",
    "        self.bias = np.zeros((1, out_dim)).astype(int)\n",
    "        self.DFA_weights = np.zeros((1, 1)).astype(int)\n",
    "\n",
    "    def forward(self, fc_in):\n",
    "        self.input = fc_in\n",
    "        dot = (self.input @ self.weights) + self.bias\n",
    "        output, self.act_grad_inv = encrypted_tanh(dot, self.in_dim, self.out_dim)\n",
    "        return output\n",
    "\n",
    "    def backward(self, loss, lr_inv):\n",
    "        d_DFA = self.compute_dDFA(loss, lr_inv)\n",
    "\n",
    "        weights_update = self.input.T @ d_DFA\n",
    "        weights_update = weights_update / lr_inv\n",
    "        weights_update = weights_update.reshape(self.in_dim, self.out_dim)\n",
    "\n",
    "        if type(self.weights.squeeze()[0][0]) is not TFHEValue:\n",
    "            self.weights = HE_client.encode_matrix(self.weights)\n",
    "\n",
    "        self.weights -= weights_update\n",
    "\n",
    "        ones = np.ones((len(d_DFA), 1)).astype(int)\n",
    "        bias_update = d_DFA.T @ ones\n",
    "        bias_update = bias_update.T / lr_inv\n",
    "\n",
    "        if type(self.bias.squeeze()[0]) is not TFHEValue:\n",
    "            self.bias = HE_client.encode_matrix(self.bias)\n",
    "\n",
    "        self.bias -= bias_update\n",
    "\n",
    "    def compute_dDFA(self, loss, lr_inv):\n",
    "        if self.last_layer:\n",
    "            d_DFA = np.divide(loss, self.act_grad_inv)\n",
    "        else:\n",
    "            if self.DFA_weights.shape[0] != loss.shape[1] and self.DFA_weights.shape[1] != self.weights.shape[1]: # 0 rows, 1 cols\n",
    "                print(\"DFA not initialized!\")\n",
    "            dot = loss @ self.DFA_weights\n",
    "            d_DFA = np.divide(dot, self.act_grad_inv)\n",
    "        return d_DFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-25T09:35:54.179251Z",
     "iopub.status.busy": "2023-01-25T09:35:54.178755Z",
     "iopub.status.idle": "2023-01-25T09:35:54.206976Z",
     "shell.execute_reply": "2023-01-25T09:35:54.204434Z"
    }
   },
   "outputs": [],
   "source": [
    "# Encrypted Network\n",
    "class EncryptedNetwork:\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "    \n",
    "    # Add layer to network\n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "    \n",
    "    # Serialize the network\n",
    "    def serialize(self):\n",
    "        for l in self.layers:\n",
    "            if hasattr(l, \"weights\"):\n",
    "                l.weights = HE_client.serialize_matrix(l.weights)\n",
    "                l.bias = HE_client.serialize_matrix(l.bias)\n",
    "                l.act_grad_inv = None\n",
    "                l.input = None\n",
    "                if not l.last_layer:\n",
    "                    l.DFA_weights = HE_client.serialize_matrix(l.DFA_weights)\n",
    "    \n",
    "    # Deserialize the network\n",
    "    def deserialize(self):\n",
    "        for l in self.layers:\n",
    "            if hasattr(l, \"weights\"):\n",
    "                l.weights = HE_client.deserialize_matrix(l.weights)\n",
    "                l.bias = HE_client.deserialize_matrix(l.bias)\n",
    "                if not l.last_layer:\n",
    "                    l.DFA_weights = HE_client.deserialize_matrix(l.DFA_weights)\n",
    "    \n",
    "    # Test\n",
    "    def test(self, x_test, y_test):\n",
    "        corr = HE_client.encode(0)\n",
    "        enc_x = HE_client.encrypt_matrix(x_test)\n",
    "        enc_y = HE_client.encrypt_matrix(y_test)\n",
    "\n",
    "        for j in range(len(x_test)):\n",
    "            pred = self.predict(enc_x[j])\n",
    "            corr = TFHEValue(HE_client.vm.gate_mux(pred == enc_y[j][0], (corr + 1).value, corr.value), corr.vm, corr.n_bits)\n",
    "        return corr\n",
    "    \n",
    "    # Predict output\n",
    "    def predict(self, input_data):\n",
    "        output = np.expand_dims(input_data, axis=0)\n",
    "        for layer in self.layers:\n",
    "            output = layer.forward(output)\n",
    "        return encrypted_argmax(output.squeeze())\n",
    "\n",
    "    # Train the network\n",
    "    def fit(self, x_train, y_train, epochs, mini_batch_size, lr_inv):\n",
    "        for i in range(epochs):\n",
    "            for j in range(int(len(x_train)/mini_batch_size)):\n",
    "                idx_start = j * mini_batch_size\n",
    "                idx_end = idx_start + mini_batch_size\n",
    "\n",
    "                batch_in = HE_client.encrypt_matrix(x_train[idx_start:idx_end])\n",
    "                batch_target = HE_client.encrypt_matrix(y_train[idx_start:idx_end])\n",
    "\n",
    "                start_time = time.time()\n",
    "\n",
    "                # Forward propagation\n",
    "                for layer in self.layers:\n",
    "                  batch_in = layer.forward(batch_in)\n",
    "                fwd_out = batch_in\n",
    "\n",
    "                end_time = time.time()\n",
    "\n",
    "                print(\"End forward batch: \" + repr(j))\n",
    "                print(\"Computation time: \")\n",
    "                hours, rem = divmod(end_time-start_time, 3600)\n",
    "                minutes, seconds = divmod(rem, 60)\n",
    "                print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "                print(\"\")\n",
    "\n",
    "                # Loss\n",
    "                loss = encrypted_L2(batch_target, fwd_out)\n",
    "               \n",
    "                start_time = time.time()\n",
    "\n",
    "                # Backward propagation\n",
    "                for layer in reversed(self.layers):\n",
    "                    layer.backward(loss, lr_inv)\n",
    "\n",
    "                end_time = time.time()\n",
    "\n",
    "                print(\"End backward batch: \" + repr(j))\n",
    "                print(\"Computation time: \")\n",
    "                hours, rem = divmod(end_time-start_time, 3600)\n",
    "                minutes, seconds = divmod(rem, 60)\n",
    "                print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "                print(\"\")\n",
    "\n",
    "            print(\"End epoch: \" + repr(i))\n",
    "            print(\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-25T09:35:54.210433Z",
     "iopub.status.busy": "2023-01-25T09:35:54.209945Z",
     "iopub.status.idle": "2023-01-25T09:35:54.219873Z",
     "shell.execute_reply": "2023-01-25T09:35:54.214791Z"
    }
   },
   "outputs": [],
   "source": [
    "## UPLOAD DFA WEIGHTS\n",
    "DFA_weights1 = np.load(\"res/dfa/DFA_weights_L1.npy\")\n",
    "DFA_weights2 = np.load(\"res/dfa/DFA_weights_L2.npy\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-25T09:35:54.223221Z",
     "iopub.status.busy": "2023-01-25T09:35:54.222744Z",
     "iopub.status.idle": "2023-01-25T09:35:54.228026Z",
     "shell.execute_reply": "2023-01-25T09:35:54.226528Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Load encrypted trained TFHE-NN-1\n",
    "# with open(\"out/model1/enc_net.pkl\", \"rb\") as f:\n",
    "#     enc_net1 = pickle.load(f)\n",
    "\n",
    "# # Load encrypted trained TFHE-NN-2\n",
    "# with open(\"out/model2/enc_net.pkl\", \"rb\") as f:\n",
    "#     enc_net2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-25T09:35:54.231030Z",
     "iopub.status.busy": "2023-01-25T09:35:54.230551Z",
     "iopub.status.idle": "2023-01-25T09:35:54.244008Z",
     "shell.execute_reply": "2023-01-25T09:35:54.240916Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Group encrypted weights\n",
    "# W2 = [enc_net1.layers[2].weights, enc_net2.layers[2].weights]\n",
    "# B2 = [enc_net1.layers[2].bias, enc_net2.layers[2].bias]\n",
    "\n",
    "# W3 = [enc_net1.layers[3].weights, enc_net2.layers[3].weights]\n",
    "# B3 = [enc_net1.layers[3].bias, enc_net2.layers[3].bias]\n",
    "\n",
    "# W4 = [enc_net1.layers[4].weights, enc_net2.layers[4].weights]\n",
    "# B4 = [enc_net1.layers[4].bias, enc_net2.layers[4].bias]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-25T09:35:54.330791Z",
     "iopub.status.busy": "2023-01-25T09:35:54.329559Z",
     "iopub.status.idle": "2023-01-25T09:35:54.344012Z",
     "shell.execute_reply": "2023-01-25T09:35:54.340755Z"
    }
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # Aggragation of encrypted weights\n",
    "# average_weights2 = encrypted_mean_matrix(W2)\n",
    "# average_bias2 = encrypted_mean_matrix(B2)\n",
    "# average_weights3 = encrypted_mean_matrix(W3)\n",
    "# average_bias3 = encrypted_mean_matrix(B3)\n",
    "# average_weights4 = encrypted_mean_matrix(W4)\n",
    "# average_bias4 = encrypted_mean_matrix(B4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-25T09:35:54.347365Z",
     "iopub.status.busy": "2023-01-25T09:35:54.346851Z",
     "iopub.status.idle": "2023-01-25T09:35:54.364011Z",
     "shell.execute_reply": "2023-01-25T09:35:54.360702Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Save decrypted trained weights\n",
    "# with open(\"res/aggregated_weights.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(HE_client.decrypt_matrix(average_weights2), f)\n",
    "#     pickle.dump(HE_client.decrypt_matrix(average_bias2), f)\n",
    "#     pickle.dump(HE_client.decrypt_matrix(average_weights3), f)\n",
    "#     pickle.dump(HE_client.decrypt_matrix(average_bias3), f)\n",
    "#     pickle.dump(HE_client.decrypt_matrix(average_weights4), f)\n",
    "#     pickle.dump(HE_client.decrypt_matrix(average_bias4), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-25T09:35:54.367037Z",
     "iopub.status.busy": "2023-01-25T09:35:54.366538Z",
     "iopub.status.idle": "2023-01-25T09:35:54.384071Z",
     "shell.execute_reply": "2023-01-25T09:35:54.380648Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load decrypted trained weights model 1\n",
    "with open(\"out/aggregation/aggregated_weights.pkl\", \"rb\") as f:\n",
    "    average_weights2 = pickle.load(f)\n",
    "    average_bias2 = pickle.load(f)\n",
    "    average_weights3 = pickle.load(f)\n",
    "    average_bias3 = pickle.load(f)\n",
    "    average_weights4 = pickle.load(f)\n",
    "    average_bias4 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-25T09:35:54.387102Z",
     "iopub.status.busy": "2023-01-25T09:35:54.386604Z",
     "iopub.status.idle": "2023-01-25T09:35:54.624081Z",
     "shell.execute_reply": "2023-01-25T09:35:54.622199Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save serialized net\n",
    "aggr_net = EncryptedNetwork()\n",
    "aggr_net.add(EncryptedMaxPoolLayer((4, 4), stride=(4, 4)))\n",
    "aggr_net.add(EncryptedFlattenLayer())\n",
    "aggr_net.add(EncryptedFCLayer(16, 4))\n",
    "aggr_net.add(EncryptedFCLayer(4, 2))\n",
    "aggr_net.add(EncryptedFCLayer(2, 3, last_layer=True))\n",
    "\n",
    "aggr_net.layers[2].DFA_weights = HE_client.encode_matrix(DFA_weights1)\n",
    "aggr_net.layers[3].DFA_weights = HE_client.encode_matrix(DFA_weights2)\n",
    "\n",
    "aggr_net.layers[2].weights = HE_client.encrypt_matrix(average_weights2)\n",
    "aggr_net.layers[2].bias = HE_client.encrypt_matrix(average_bias2)\n",
    "aggr_net.layers[3].weights = HE_client.encrypt_matrix(average_weights3)\n",
    "aggr_net.layers[3].bias = HE_client.encrypt_matrix(average_bias3)\n",
    "aggr_net.layers[4].weights = HE_client.encrypt_matrix(average_weights4)\n",
    "aggr_net.layers[4].bias = HE_client.encrypt_matrix(average_bias4)\n",
    "\n",
    "aggr_net.serialize()\n",
    "\n",
    "with open(\"out/aggregation/enc_net.pkl\", \"wb\") as f:\n",
    "  pickle.dump(aggr_net, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-25T09:35:54.628249Z",
     "iopub.status.busy": "2023-01-25T09:35:54.627666Z",
     "iopub.status.idle": "2023-01-25T09:35:54.637340Z",
     "shell.execute_reply": "2023-01-25T09:35:54.636811Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load decrypted trained weights model 1\n",
    "with open(\"out/model1/trained_weights.pkl\", \"rb\") as f:\n",
    "    weights2_M1 = pickle.load(f)\n",
    "    bias2_M1 = pickle.load(f)\n",
    "    weights3_M1 = pickle.load(f)\n",
    "    bias3_M1 = pickle.load(f)\n",
    "    weights4_M1 = pickle.load(f)\n",
    "    bias4_M1 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-25T09:35:54.646137Z",
     "iopub.status.busy": "2023-01-25T09:35:54.645610Z",
     "iopub.status.idle": "2023-01-25T09:35:54.832106Z",
     "shell.execute_reply": "2023-01-25T09:35:54.829542Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save serialized net\n",
    "enc_net1 = EncryptedNetwork()\n",
    "enc_net1.add(EncryptedMaxPoolLayer((4, 4), stride=(4, 4)))\n",
    "enc_net1.add(EncryptedFlattenLayer())\n",
    "enc_net1.add(EncryptedFCLayer(16, 4))\n",
    "enc_net1.add(EncryptedFCLayer(4, 2))\n",
    "enc_net1.add(EncryptedFCLayer(2, 3, last_layer=True))\n",
    "\n",
    "enc_net1.layers[2].DFA_weights = HE_client.encode_matrix(DFA_weights1)\n",
    "enc_net1.layers[3].DFA_weights = HE_client.encode_matrix(DFA_weights2)\n",
    "\n",
    "enc_net1.layers[2].weights = HE_client.encrypt_matrix(weights2_M1)\n",
    "enc_net1.layers[2].bias = HE_client.encrypt_matrix(bias2_M1)\n",
    "enc_net1.layers[3].weights = HE_client.encrypt_matrix(weights3_M1)\n",
    "enc_net1.layers[3].bias = HE_client.encrypt_matrix(bias3_M1)\n",
    "enc_net1.layers[4].weights = HE_client.encrypt_matrix(weights4_M1)\n",
    "enc_net1.layers[4].bias = HE_client.encrypt_matrix(bias4_M1)\n",
    "\n",
    "enc_net1.serialize()\n",
    "\n",
    "with open(\"out/model1/enc_net.pkl\", \"wb\") as f:\n",
    "  pickle.dump(enc_net1, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-25T09:35:54.848961Z",
     "iopub.status.busy": "2023-01-25T09:35:54.845665Z",
     "iopub.status.idle": "2023-01-25T09:35:54.867876Z",
     "shell.execute_reply": "2023-01-25T09:35:54.860606Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load decrypted trained weights model 2\n",
    "with open(\"out/model2/trained_weights.pkl\", \"rb\") as f:\n",
    "    weights2_M2 = pickle.load(f)\n",
    "    bias2_M2 = pickle.load(f)\n",
    "    weights3_M2 = pickle.load(f)\n",
    "    bias3_M2 = pickle.load(f)\n",
    "    weights4_M2 = pickle.load(f)\n",
    "    bias4_M2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-25T09:35:54.884200Z",
     "iopub.status.busy": "2023-01-25T09:35:54.879382Z",
     "iopub.status.idle": "2023-01-25T09:35:55.040013Z",
     "shell.execute_reply": "2023-01-25T09:35:55.035375Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save serialized net\n",
    "enc_net2 = EncryptedNetwork()\n",
    "enc_net2.add(EncryptedMaxPoolLayer((4, 4), stride=(4, 4)))\n",
    "enc_net2.add(EncryptedFlattenLayer())\n",
    "enc_net2.add(EncryptedFCLayer(16, 4))\n",
    "enc_net2.add(EncryptedFCLayer(4, 2))\n",
    "enc_net2.add(EncryptedFCLayer(2, 3, last_layer=True))\n",
    "\n",
    "enc_net2.layers[2].DFA_weights = HE_client.encode_matrix(DFA_weights1)\n",
    "enc_net2.layers[3].DFA_weights = HE_client.encode_matrix(DFA_weights2)\n",
    "\n",
    "enc_net2.layers[2].weights = HE_client.encrypt_matrix(weights2_M2)\n",
    "enc_net2.layers[2].bias = HE_client.encrypt_matrix(bias2_M2)\n",
    "enc_net2.layers[3].weights = HE_client.encrypt_matrix(weights3_M2)\n",
    "enc_net2.layers[3].bias = HE_client.encrypt_matrix(bias3_M2)\n",
    "enc_net2.layers[4].weights = HE_client.encrypt_matrix(weights4_M2)\n",
    "enc_net2.layers[4].bias = HE_client.encrypt_matrix(bias4_M2)\n",
    "\n",
    "enc_net2.serialize()\n",
    "\n",
    "with open(\"out/model2/enc_net.pkl\", \"wb\") as f:\n",
    "  pickle.dump(enc_net2, f)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNDVK1GUNs7ICExTzMIGeYt",
   "collapsed_sections": [],
   "name": "PyCrCNN_PocketNN_Training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
